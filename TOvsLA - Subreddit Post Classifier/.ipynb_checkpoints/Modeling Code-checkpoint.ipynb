{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "okay, so there isn't a clear real utility for the simple classification of post into a subreddit. For one, 100% of posts on reddit belong to a subreddit so a post would always have its subreddit attached to it.  It's just obviously not very impressive in utility.  At first glance, that is.\n",
    "\n",
    "The process of creating a binary classifier can bring to light some other factors about whatever's being studied. Keeping in mind that the sample of information they're getting from is demographically biased so there are limitations in its generaliztion to many other applications. \n",
    "\n",
    "Learning about what keywords are most important to a city may give you an idea about the culture in the city, or what's important to the city. So many things could be discovered from this sort of exploration. Could also be used in market research analysis (yawn) by comparing one brand's subreddit with another's. Or, one show's fanbase vs another's. This binary classification model can also be modified to be applied to message filters (like sorting out spam from emails).\n",
    "\n",
    "Application doesn't end there, however...Sociologists would have a field day with this tool due to its far-reaching applications in thematic analyses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gabriela Osorio\n",
    "#### DSI Project 3 - Creating a Binary Subreddit Classifier - TO vs. LA\n",
    "#### November 5, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preamble\n",
    ">  Reddit is an online public content sharing platform that is organized into different categories known as subreddits. Subreddits are comprised of user-submitted posts that can be text, media, or both. Posts can be interacted with through user-prompted upvotes, downvotes, comments, and of course, views. This project will outline the creation of a subreddit classifier that predicts the subreddit a given post is from. Specifially, it's a binary classifier for the Toronto and Los Angeles subreddits. This model can then be expanded upon to explore what the most important characteristics are of this classifier.\n",
    "\n",
    "#### Quick Model Summary\n",
    "> **Input**: 'Title' <br>\n",
    "**Output**: Binary label ('LA' or 'TO')<br>\n",
    "**Type**: Binary Classifier: Random Forest, Support Vector Machine <br>\n",
    "**Metrics of Success**: Accuracy <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: Webscraping Using the Reddit API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by scraping posts from the Toronto and LA subreddits using Reddit's API. This portion was created from a template provided by Max Humber, course instructor, so it should not be mistaken for the author's original work. \n",
    "\n",
    "Potentially interesting and influential features of posts that have been identified and included in this webscraping include: \n",
    "- subreddit: to be part of the target vector later on \n",
    "- title: text input  \n",
    "- selftext : actual text from the post\n",
    "- downs : upvotes, positive points\n",
    "- ups : downvotes, negative points\n",
    "- num_comments : number of comments\n",
    "- permalink \n",
    "- name \n",
    "- author \n",
    "- is_original_content : binary answer to \"Is content in selftext original?\"\n",
    "- edited : binary answer to \"Has this post been edited?\"\n",
    "- media_only : binary answer to \"Does the post only have a photo?\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1A: Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1B: Creating and Exporting Scraped Goods as CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#now = str(datetime.datetime.now())[:19]\n",
    "\n",
    "#filename = f'data/datasci scrape {now}.csv'\n",
    "#filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn import svm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(965, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TO=pd.read_csv('./data/TO.csv')\n",
    "TO.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(970, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA= pd.read_csv('./data/LA.csv')\n",
    "LA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author                 object\n",
       "downs                   int64\n",
       "edited                 object\n",
       "is_original_content      bool\n",
       "media_only               bool\n",
       "name                   object\n",
       "num_comments            int64\n",
       "permalink              object\n",
       "selftext               object\n",
       "subreddit              object\n",
       "title                  object\n",
       "ups                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities=[TO,LA]\n",
    "tola=pd.concat(cities)\n",
    "tola.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's hold our horses here.\n",
    "Though we extracted many potential features for our upcoming predictive models, we'll only be focusing on title for now in this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Later, we might get to use this as our features: **X=tola.drop(columns='subreddit')**\n",
    "\n",
    "For now though, we'll stick to X='Title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1935, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tola.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>downs</th>\n",
       "      <th>edited</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>media_only</th>\n",
       "      <th>name</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>westondeboer</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_9pew82</td>\n",
       "      <td>3</td>\n",
       "      <td>/r/LosAngeles/comments/9pew82/helicopter_makes...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LosAngeles</td>\n",
       "      <td>Helicopter makes emergency landing in Dodger S...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>max_raid</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_9pltyt</td>\n",
       "      <td>6</td>\n",
       "      <td>/r/LosAngeles/comments/9pltyt/spectrum_interne...</td>\n",
       "      <td>In Encino and haven't had internet since I wok...</td>\n",
       "      <td>LosAngeles</td>\n",
       "      <td>Spectrum Internet Outage?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>throwdatwey</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_9ph8al</td>\n",
       "      <td>7</td>\n",
       "      <td>/r/LosAngeles/comments/9ph8al/flash_in_the_sky/</td>\n",
       "      <td>Just saw a huge flash in what I believe was th...</td>\n",
       "      <td>LosAngeles</td>\n",
       "      <td>Flash in the sky?</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>comolaflor24</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_9pagh0</td>\n",
       "      <td>12</td>\n",
       "      <td>/r/LosAngeles/comments/9pagh0/car_broke_down_o...</td>\n",
       "      <td>Shout out to the random good Samaritans who he...</td>\n",
       "      <td>LosAngeles</td>\n",
       "      <td>Car broke down on the Expo Line track</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>BlankVerse</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_9pd0yq</td>\n",
       "      <td>53</td>\n",
       "      <td>/r/LosAngeles/comments/9pd0yq/least_shocking_n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LosAngeles</td>\n",
       "      <td>Least shocking news ever: Report says owners d...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author  downs edited  is_original_content  media_only       name  \\\n",
       "965  westondeboer      0  False                False       False  t3_9pew82   \n",
       "966      max_raid      0  False                False       False  t3_9pltyt   \n",
       "967   throwdatwey      0  False                False       False  t3_9ph8al   \n",
       "968  comolaflor24      0  False                False       False  t3_9pagh0   \n",
       "969    BlankVerse      0  False                False       False  t3_9pd0yq   \n",
       "\n",
       "     num_comments                                          permalink  \\\n",
       "965             3  /r/LosAngeles/comments/9pew82/helicopter_makes...   \n",
       "966             6  /r/LosAngeles/comments/9pltyt/spectrum_interne...   \n",
       "967             7    /r/LosAngeles/comments/9ph8al/flash_in_the_sky/   \n",
       "968            12  /r/LosAngeles/comments/9pagh0/car_broke_down_o...   \n",
       "969            53  /r/LosAngeles/comments/9pd0yq/least_shocking_n...   \n",
       "\n",
       "                                              selftext   subreddit  \\\n",
       "965                                                NaN  LosAngeles   \n",
       "966  In Encino and haven't had internet since I wok...  LosAngeles   \n",
       "967  Just saw a huge flash in what I believe was th...  LosAngeles   \n",
       "968  Shout out to the random good Samaritans who he...  LosAngeles   \n",
       "969                                                NaN  LosAngeles   \n",
       "\n",
       "                                                 title  ups  \n",
       "965  Helicopter makes emergency landing in Dodger S...   24  \n",
       "966                          Spectrum Internet Outage?    1  \n",
       "967                                  Flash in the sky?    5  \n",
       "968              Car broke down on the Expo Line track   96  \n",
       "969  Least shocking news ever: Report says owners d...   34  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tola.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stopwords = stopwords.words('english')\n",
    "my_stopwords.extend(['amp','x200b','\\n'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7304625199362041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Posts missing their text'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(((tola['selftext'].isnull().sum())/1881)),\n",
    "'Posts missing their text'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get ready to set up our actual experiment now! As we just saw, about 73% of our data points don't have any text in the post and are just a title.\n",
    " Our X aka features will be the string titles, and our y aka target will be the TO and LA labels. Right now those values are in string format and say either toronto or losangeles. So we will change our target's values to floats that are binary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         toronto\n",
       "1         toronto\n",
       "2         toronto\n",
       "3         toronto\n",
       "4         toronto\n",
       "5         toronto\n",
       "6         toronto\n",
       "7         toronto\n",
       "8         toronto\n",
       "9         toronto\n",
       "10        toronto\n",
       "11        toronto\n",
       "12        toronto\n",
       "13        toronto\n",
       "14        toronto\n",
       "15        toronto\n",
       "16        toronto\n",
       "17        toronto\n",
       "18        toronto\n",
       "19        toronto\n",
       "20        toronto\n",
       "21        toronto\n",
       "22        toronto\n",
       "23        toronto\n",
       "24        toronto\n",
       "25        toronto\n",
       "26        toronto\n",
       "27        toronto\n",
       "28        toronto\n",
       "29        toronto\n",
       "          ...    \n",
       "940    LosAngeles\n",
       "941    LosAngeles\n",
       "942    LosAngeles\n",
       "943    LosAngeles\n",
       "944    LosAngeles\n",
       "945    LosAngeles\n",
       "946    LosAngeles\n",
       "947    LosAngeles\n",
       "948    LosAngeles\n",
       "949    LosAngeles\n",
       "950    LosAngeles\n",
       "951    LosAngeles\n",
       "952    LosAngeles\n",
       "953    LosAngeles\n",
       "954    LosAngeles\n",
       "955    LosAngeles\n",
       "956    LosAngeles\n",
       "957    LosAngeles\n",
       "958    LosAngeles\n",
       "959    LosAngeles\n",
       "960    LosAngeles\n",
       "961    LosAngeles\n",
       "962    LosAngeles\n",
       "963    LosAngeles\n",
       "964    LosAngeles\n",
       "965    LosAngeles\n",
       "966    LosAngeles\n",
       "967    LosAngeles\n",
       "968    LosAngeles\n",
       "969    LosAngeles\n",
       "Name: subreddit, Length: 1935, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tola['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tola['title']\n",
    "tola['subreddit'].replace({'toronto': 1, 'LosAngeles': 0}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=tola['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.2, random_state=42)\n",
    "tfidvec = TfidfVectorizer(stop_words = my_stopwords)\n",
    "tfidvec.fit(X_train)\n",
    "X_train= tfidvec.transform(X_train)\n",
    "X_test = tfidvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so now we have the values in matrices or dataframes. We're ready to model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3A: Selecting and Fitting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "building out a function to get back info from the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def conf_matrix(model, X_test):\n",
    "    \n",
    "    y_pred = model.predict(X_test)            \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    acc=round(accuracy_score(y_test,y_pred),2)\n",
    "    tn, fp, fn, tp = cm.ravel()                \n",
    "    print(f\"True Negatives: {tn}\")            \n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "    print(f\"True Positives: {tp}\") \n",
    "    print(f\"Accuracy Score:{acc}\")\n",
    "    return pd.DataFrame(cm, columns = ['Predicted TO','Predicted LA'], index = ['Actual TO', 'Actual LA'])\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Support Vector Machine**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out a Support Vector Machine (for the first time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 169\n",
      "False Positives: 25\n",
      "False Negatives: 31\n",
      "True Positives: 162\n",
      "Accuracy Score:0.86\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted TO</th>\n",
       "      <th>Predicted LA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual TO</th>\n",
       "      <td>169</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual LA</th>\n",
       "      <td>31</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted TO  Predicted LA\n",
       "Actual TO           169            25\n",
       "Actual LA            31           162"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC(gamma=.6)\n",
    "svc.fit(X_train, y_train)\n",
    "conf_matrix(svc, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 177\n",
      "False Positives: 17\n",
      "False Negatives: 52\n",
      "True Positives: 141\n",
      "Accuracy Score:0.82\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted TO</th>\n",
       "      <th>Predicted LA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual TO</th>\n",
       "      <td>177</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual LA</th>\n",
       "      <td>52</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted TO  Predicted LA\n",
       "Actual TO           177            17\n",
       "Actual LA            52           141"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "conf_matrix(rfc, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Adaptive Boosting** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 187\n",
      "False Positives: 7\n",
      "False Negatives: 78\n",
      "True Positives: 115\n",
      "Accuracy Score:0.78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted TO</th>\n",
       "      <th>Predicted LA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual TO</th>\n",
       "      <td>187</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual LA</th>\n",
       "      <td>78</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted TO  Predicted LA\n",
       "Actual TO           187             7\n",
       "Actual LA            78           115"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada=AdaBoostClassifier()\n",
    "ada.fit(X_train, y_train)\n",
    "conf_matrix(ada, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Basic Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 170\n",
      "False Positives: 24\n",
      "False Negatives: 32\n",
      "True Positives: 161\n",
      "Accuracy Score:0.86\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted TO</th>\n",
       "      <th>Predicted LA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual TO</th>\n",
       "      <td>170</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual LA</th>\n",
       "      <td>32</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted TO  Predicted LA\n",
       "Actual TO           170            24\n",
       "Actual LA            32           161"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "conf_matrix(lr, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** -----------------------------------------------------------------------------\n",
    "- 4 models: Basic logistic regression, random forest classifier, adaptive boosting, and support vector machine have achieved accuracy scores of 86 and above. \n",
    "\n",
    "We'll now apply **GridSearchCV** to these models to optimize their parameters and automate the best possible options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3B: Optimizing Models' Parameters for Highest Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Optimizing the Linear Regression:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8552971576227391\n",
      "0.49870801033591733\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs', max_iter=200) \n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(lr.score(X_test, y_test))\n",
    "print(np.mean(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_params = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'solver':['liblinear'],\n",
    "    'C':np.logspace(-5,0,100)\n",
    "}\n",
    "\n",
    "lr_gridsearch = GridSearchCV(LogisticRegression(), gs_params, cv=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_gridsearch = lr_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That was pretty tedious work for just optimizing one model. We'll now look to our knowledge of class, functions, and dictionaries to optimize all functions automatically. The EstimatorSelectionHelper code is originally from David S. Batista. I've modified it for use in Python 3 with sklearn's current library.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EstimatorSelectionHelper:\n",
    "    \n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "    \n",
    "    def fit(self, X, y, **grid_kwargs):\n",
    "        for key in self.keys:\n",
    "            print('Running GridSearchCV for %s.' % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            grid_search = GridSearchCV(model, params, **grid_kwargs)\n",
    "            grid_search.fit(X, y)\n",
    "            self.grid_searches[key] = grid_search\n",
    "        print('Done.')\n",
    "    \n",
    "    def score_summary(self, sort_by='mean_test_score'):\n",
    "        frames = []\n",
    "        for name, grid_search in self.grid_searches.items():\n",
    "            frame = pd.DataFrame(grid_search.cv_results_)\n",
    "            frame = frame.filter(regex='^(?!.*param_).*$')\n",
    "            frame['estimator'] = len(frame)*[name]\n",
    "            frames.append(frame)\n",
    "        df = pd.concat(frames)\n",
    "        \n",
    "        df = df.sort_values([sort_by], ascending=False)\n",
    "        df = df.reset_index()\n",
    "        df = df.drop(['rank_test_score', 'index'], 1)\n",
    "        \n",
    "        columns = df.columns.tolist()\n",
    "        columns.remove('estimator')\n",
    "        columns = ['estimator']+columns\n",
    "        df = df[columns]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models1 = { \n",
    "    'SVC': svc,\n",
    "    'RandomForestClassifier': rfc,\n",
    "    'AdaBoostClassifier': ada,\n",
    "    \n",
    "}\n",
    "\n",
    "params1 = {\n",
    "    'SVC': [\n",
    "        {'kernel': ['linear'], 'C': [1, 10], 'gamma': [0.001, 0.01, 1, 10]},\n",
    "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]}], \n",
    "    'RandomForestClassifier': {'bootstrap': [True, False],\n",
    "                                'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "                                 'max_features': ['auto', 'sqrt'],\n",
    "                                 'min_samples_leaf': [1, 2, 4],\n",
    "                                 'min_samples_split': [2, 5, 10],\n",
    "                                'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]},\n",
    "    'AdaBoostClassifier':  { 'n_estimators': [16, 32] }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper1 = EstimatorSelectionHelper(models1, params1)\n",
    "helper1.fit(X_test, y_test, return_train_score=True, n_jobs=2)\n",
    "df=helper1.score_summary()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[['estimator','params', 'mean_test_score', 'std_test_score',\n",
    "       'mean_train_score', 'std_train_score']]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
